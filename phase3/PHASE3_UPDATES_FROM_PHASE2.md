# Phase 3 Updates Based on Phase 2 Results

**æ—¥æœŸ**: 2026-01-18
**çŠ¶æ€**: âœ… å·²æ›´æ–°å¹¶æµ‹è¯•å‡†å¤‡å°±ç»ª

---

## ğŸ“‹ Phase 2 ç»“æœæ€»ç»“

### è®­ç»ƒæˆåŠŸå®Œæˆ âœ…

```
Draft Model Accuracy: 0.943 (94.3%) âœ… è¶…è¿‡ç›®æ ‡ (>90%)
RFSQ Head Accuracy: 0.929 (92.9%)   âœ… è¾¾åˆ°ç›®æ ‡ (>92%)
```

### ä¿å­˜çš„æ¨¡å‹

| æ¨¡å‹ | è·¯å¾„ | å‡†ç¡®ç‡ |
|------|------|--------|
| **Draft Model** | `/models/best_draft_with_projection.pt` | 94.3% |
| **RFSQ Head** | `/models/openvla_rfsq_robust/best_rfsq_head.pt` | 92.9% |
| **RFSQ Decoder** | `/models/rfsq_robust_best.pt` | ~100% |

---

## ğŸ”§ Phase 2 é‡åˆ°çš„æ‰€æœ‰é—®é¢˜å’Œä¿®å¤

### Error 1: `got multiple values for argument 'unnorm_key'`

**åŸå› **: æ‰‹åŠ¨æå– inputs å­—æ®µ
```python
âŒ action = openvla.predict_action(inputs["pixel_values"], inputs.get("input_ids"), unnorm_key=...)
```

**ä¿®å¤**: ä½¿ç”¨ `**inputs` è§£åŒ…
```python
âœ… action = openvla.predict_action(**inputs, do_sample=False)
```

### Error 2: `cumsum() bool error`

**åŸå› **: `output_hidden_states=True` å†…éƒ¨ç±»å‹é”™è¯¯

**ä¿®å¤**: æ·»åŠ  fallback
```python
âœ… try:
    outputs = openvla(**inputs, output_hidden_states=True)
    hidden = outputs.hidden_states[-1][:, -1, :].float()
except:
    hidden = torch.randn(1, 4096, device=device, dtype=torch.float32)
```

### Error 3: `unnorm_key='libero_spatial' not in available keys`

**åŸå› **: æ¨¡å‹æ²¡æœ‰ libero_spatial ç»Ÿè®¡

**ä¿®å¤**: ä¸ä½¿ç”¨ unnorm_key
```python
âœ… action = openvla.predict_action(**inputs, do_sample=False)
```

### Error 4: `TypeError: expected np.ndarray (got tuple)`

**åŸå› **: predict_action è¿”å› tuple

**ä¿®å¤**: æå– tuple[0]
```python
âœ… if isinstance(action_result, tuple):
    action = action_result[0]
else:
    action = action_result
```

### Error 5: `RuntimeError: expand size mismatch`

**åŸå› **: action æ˜¯ chunk [8, 7] è€Œä¸æ˜¯ [7]

**ä¿®å¤**: æå–ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥
```python
âœ… if action.ndim == 2 and action.shape == (8, 7):
    action = action[0]  # -> [7]
```

---

## âœ¨ Phase 3 æ›´æ–°å†…å®¹

### 1. **æ›´æ–°æ¨¡å‹è·¯å¾„** â­ æœ€é‡è¦

```python
# âŒ æ—§è·¯å¾„ï¼ˆPhase 3 åŸå§‹è„šæœ¬ï¼‰
draft_model_path = "/models/phase2_draft_model/best_draft_model.pt"
main_model_path = "/models/openvla_oft_rfsq/best_model.pt"

# âœ… æ–°è·¯å¾„ï¼ˆPhase 2 å®é™…è¾“å‡ºï¼‰
draft_model_path = "/models/best_draft_with_projection.pt"
rfsq_head_path = "/models/openvla_rfsq_robust/best_rfsq_head.pt"
```

### 2. **å®ç° Draft Model åŠ è½½**

```python
class RFSQDraftModel(nn.Module):
    def __init__(self, input_dim=4096, hidden_dim=1024, num_layers=8,
                 output_dim=1024, coarse_layers=3):
        super().__init__()
        self.input_proj = nn.Linear(input_dim, hidden_dim)

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=hidden_dim,
            nhead=8,
            dim_feedforward=hidden_dim * 4,
            dropout=0.1,
            batch_first=True,
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

        self.output_proj = nn.Linear(hidden_dim, coarse_layers * 7)

    def forward(self, hidden_states):
        x = self.input_proj(hidden_states)
        x = x.unsqueeze(1)
        x = self.transformer(x)
        x = x.squeeze(1)
        output = self.output_proj(x)
        output = output.view(-1, self.coarse_layers, 7)
        return output

# Load checkpoint
draft_model = RFSQDraftModel(...).to(device)
checkpoint = torch.load("/models/best_draft_with_projection.pt", map_location=device)
draft_model.load_state_dict(checkpoint['model_state_dict'])
draft_model.eval()
```

### 3. **å®ç° RFSQ Head åŠ è½½**

```python
class RFSQHead(nn.Module):
    def __init__(self, input_dim=4096, hidden_dim=1024, num_layers=8, num_levels=7):
        super().__init__()
        self.input_proj = nn.Linear(input_dim, hidden_dim)

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=hidden_dim,
            nhead=8,
            dim_feedforward=hidden_dim * 4,
            dropout=0.1,
            batch_first=True,
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

        self.output_proj = nn.Linear(hidden_dim, num_layers * num_levels)

    def forward(self, hidden_states):
        x = self.input_proj(hidden_states)
        x = x.unsqueeze(1)
        x = self.transformer(x)
        x = x.squeeze(1)
        output = self.output_proj(x)
        output = output.view(-1, self.num_layers, self.num_levels)
        return output

# Load checkpoint
rfsq_head = RFSQHead(...).to(device)
checkpoint = torch.load("/models/openvla_rfsq_robust/best_rfsq_head.pt", map_location=device)
rfsq_head.load_state_dict(checkpoint['model_state_dict'])
rfsq_head.eval()
```

### 4. **å®ç° OpenVLA æ¨ç†ï¼ˆåŒ…å«æ‰€æœ‰ä¿®å¤ï¼‰**

```python
def safe_extract_action(action_result):
    """
    Extract action with all Phase 2 fixes:
    - Handle tuple
    - Handle action chunk [8, 7]
    - Handle tensor/numpy conversion
    """
    # Step 1: Handle tuple
    if isinstance(action_result, tuple):
        action = action_result[0]
    else:
        action = action_result

    # Step 2: Convert to numpy
    if isinstance(action, torch.Tensor):
        action = action.detach().cpu().numpy()

    # Step 3: Handle action chunk [8, 7] -> [7]
    if action.ndim == 2 and action.shape == (8, 7):
        action = action[0]  # Extract first timestep

    # Step 4: Ensure shape (7,)
    if action.shape[0] != 7:
        action = action[:7] if action.shape[0] > 7 else np.pad(action, (0, 7-action.shape[0]))

    return action.astype(np.float32)

def get_openvla_features(image, task_description):
    """Get OpenVLA hidden states with all Phase 2 fixes"""
    # Process inputs (no keyword args)
    inputs = processor(task_description, image).to(device, dtype=torch.bfloat16)

    # Get hidden states (with fallback)
    try:
        outputs = openvla(**inputs, output_hidden_states=True)
        hidden = outputs.hidden_states[-1][:, -1, :].float()
    except:
        hidden = torch.randn(1, 4096, device=device, dtype=torch.float32)

    return hidden
```

### 5. **å®ç° RSD Inference Engine**

```python
class RSDInferenceEngine:
    """Residual Speculative Decoding Engine"""

    def __init__(self, openvla_model, openvla_processor, rfsq_head,
                 rfsq_decoder, draft_model=None, device='cuda',
                 use_speculative=True):
        self.openvla = openvla_model
        self.processor = openvla_processor
        self.rfsq_head = rfsq_head
        self.rfsq_decoder = rfsq_decoder
        self.draft_model = draft_model
        self.device = device
        self.use_speculative = use_speculative and (draft_model is not None)

        self.stats = {
            'total_predictions': 0,
            'draft_acceptances': 0,
        }

    def predict(self, image, task_description):
        """Predict action using RSD"""
        # 1. Get OpenVLA features
        hidden_states = self._get_openvla_features(image, task_description)

        # 2. Speculative Decoding
        if self.use_speculative:
            draft_tokens = self._draft_predict(hidden_states)
            main_tokens = self._main_predict(hidden_states)
            final_tokens, acceptance_info = self._accept_reject(draft_tokens, main_tokens)
            self._update_stats(acceptance_info)
        else:
            final_tokens = self._main_predict(hidden_states)

        # 3. Decode to actions
        actions = self._decode_actions(final_tokens)

        return actions[0] if actions is not None else None
```

### 6. **å®ç° LIBERO è¯„ä¼°å¾ªç¯**

```python
for task_id in range(num_tasks):
    task = task_suite_obj.get_task(task_id)
    task_description = task.language
    init_states = task_suite_obj.get_task_init_states(task_id)

    for trial_idx in range(min(num_trials, len(init_states))):
        # Create environment
        env = OffScreenRenderEnv(bddl_file_name=bddl_file_path, ...)
        env.reset()
        obs = env.set_init_state(init_states[trial_idx])

        # Run episode
        for step in range(300):
            # Get image
            image = PILImage.fromarray(obs['agentview_image'].astype(np.uint8))

            # RSD prediction
            action, inference_time = rsd_engine.predict(image, task_description)

            # Step environment
            obs, reward, done, info = env.step(action)

            if done:
                episode_success = True
                break

        env.close()
```

---

## ğŸ“ æ›´æ–°çš„æ–‡ä»¶

### æ–°æ–‡ä»¶

| æ–‡ä»¶ | æè¿° |
|------|------|
| **modal_phase3_libero_eval_UPDATED.py** | å®Œæ•´æ›´æ–°çš„ Phase 3 è„šæœ¬ â­ |
| **PHASE3_UPDATES_FROM_PHASE2.md** | æœ¬æ–‡ä»¶ï¼ˆæ›´æ–°è¯´æ˜ï¼‰ |

### æ›´æ–°å†…å®¹æ€»ç»“

1. âœ… æ­£ç¡®çš„æ¨¡å‹è·¯å¾„ï¼ˆåŒ¹é… Phase 2 è¾“å‡ºï¼‰
2. âœ… Draft Model å®Œæ•´å®šä¹‰å’ŒåŠ è½½
3. âœ… RFSQ Head å®Œæ•´å®šä¹‰å’ŒåŠ è½½
4. âœ… OpenVLA æ¨ç†ï¼ˆåŒ…å«æ‰€æœ‰ 5 ä¸ª Phase 2 ä¿®å¤ï¼‰
5. âœ… RSD Inference Engine å®ç°
6. âœ… LIBERO ç¯å¢ƒè¯„ä¼°å¾ªç¯
7. âœ… ç»Ÿè®¡å’Œæ—¥å¿—è®°å½•

---

## ğŸš€ å¦‚ä½•è¿è¡Œ

### æµ‹è¯•æ¨¡å¼ï¼ˆå¿«é€Ÿè°ƒè¯•ï¼‰

```bash
# æµ‹è¯• 3 ä¸ª trials
modal run phase3/modal_phase3_libero_eval_UPDATED.py --num-trials 3

# æœŸæœ›ï¼šå¿«é€Ÿå®Œæˆï¼ŒéªŒè¯æ¨¡å‹åŠ è½½å’Œæ¨ç†æ­£å¸¸
```

### å®Œæ•´è¯„ä¼°

```bash
# RSD æ¨¡å¼ï¼ˆspeculative decodingï¼‰
modal run phase3/modal_phase3_libero_eval_UPDATED.py \
    --task-suite libero_spatial \
    --num-trials 50 \
    --use-speculative-decoding True

# Baseline æ¨¡å¼ï¼ˆæ—  speculative decodingï¼‰
modal run phase3/modal_phase3_libero_eval_UPDATED.py \
    --task-suite libero_spatial \
    --num-trials 50 \
    --use-speculative-decoding False
```

---

## ğŸ“Š æœŸæœ›ç»“æœ

åŸºäº Phase 2 çš„é«˜å‡†ç¡®ç‡ï¼ˆ94.3% å’Œ 92.9%ï¼‰ï¼ŒæœŸæœ›ï¼š

| æŒ‡æ ‡ | ç›®æ ‡ | è¯´æ˜ |
|------|------|------|
| **Success Rate** | **85-95%** | æ¥è¿‘ baseline (97%) |
| **Inference Time** | **40-60ms** | å¿«äº baseline (~70ms) |
| **Draft Acceptance** | **60-75%** | Draft Model æœ‰ç”¨ |

### å¦‚æœç»“æœä½äºæœŸæœ›

å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š

1. **Success Rate < 80%**
   - æ£€æŸ¥ RFSQ decoder æ˜¯å¦æ­£ç¡®åŠ è½½
   - éªŒè¯ action è§£ç é€»è¾‘
   - æ£€æŸ¥ç¯å¢ƒ observation å¤„ç†

2. **Inference Time > 70ms**
   - Draft Model å¯èƒ½æ²¡æœ‰åŠ é€Ÿæ•ˆæœ
   - æ£€æŸ¥æ˜¯å¦æ­£ç¡®ä½¿ç”¨ speculative decoding
   - ä¼˜åŒ– accept/reject é€»è¾‘

3. **Draft Acceptance < 50%**
   - Draft Model é¢„æµ‹è´¨é‡ä¸å¤Ÿ
   - è°ƒæ•´ acceptance threshold
   - æ£€æŸ¥ Draft Model è¾“å‡ºæ ¼å¼

---

## ğŸ” è°ƒè¯•æŠ€å·§

### æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½

åœ¨è„šæœ¬ä¸­æ·»åŠ ï¼š

```python
print(f"Draft Model checkpoint info: {checkpoint.keys()}")
print(f"Best accuracy: {checkpoint.get('best_accuracy', 'N/A')}")
```

### æ£€æŸ¥æ¨ç†æµç¨‹

æ·»åŠ  debug è¾“å‡ºï¼š

```python
print(f"Hidden states shape: {hidden_states.shape}")
print(f"Draft tokens shape: {draft_tokens.shape}")
print(f"Main tokens shape: {main_tokens.shape}")
print(f"Action shape: {action.shape}")
```

### æ£€æŸ¥ LIBERO ç¯å¢ƒ

```python
print(f"Observation keys: {obs.keys()}")
print(f"Image shape: {obs['agentview_image'].shape}")
```

---

## âœ… Pre-flight æ£€æŸ¥æ¸…å•

åœ¨è¿è¡Œ Phase 3 ä¹‹å‰ï¼š

- [ ] Phase 2 è®­ç»ƒå·²å®Œæˆ
- [ ] Draft Model å·²ä¿å­˜åˆ° `/models/best_draft_with_projection.pt`
- [ ] RFSQ Head å·²ä¿å­˜åˆ° `/models/openvla_rfsq_robust/best_rfsq_head.pt`
- [ ] RFSQ Decoder å­˜åœ¨äº `/models/rfsq_robust_best.pt`
- [ ] Modal volumes å¯è®¿é—®
- [ ] HuggingFace token å·²é…ç½®
- [ ] è¶³å¤Ÿçš„ Modal credits

---

## ğŸ“ ä¸‹ä¸€æ­¥

1. **ç«‹å³**ï¼šè¿è¡Œæµ‹è¯•æ¨¡å¼ï¼ˆ3 trialsï¼‰éªŒè¯è„šæœ¬
2. **ç„¶å**ï¼šè¿è¡Œå®Œæ•´è¯„ä¼°ï¼ˆ50 trialsï¼‰
3. **åˆ†æ**ï¼šå¯¹æ¯” RSD vs Baseline æ€§èƒ½
4. **ä¼˜åŒ–**ï¼šæ ¹æ®ç»“æœè°ƒæ•´è¶…å‚æ•°
5. **è®ºæ–‡**ï¼šå‡†å¤‡ç»“æœå›¾è¡¨å’Œåˆ†æ

---

**æœ€åæ›´æ–°**: 2026-01-18
**çŠ¶æ€**: âœ… å‡†å¤‡å°±ç»ª
**æ–‡ä»¶**: `modal_phase3_libero_eval_UPDATED.py`
