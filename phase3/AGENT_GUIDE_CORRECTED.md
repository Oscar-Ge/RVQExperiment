# ğŸ¯ Phase 3 æ­£ç¡®å®ç°æŒ‡å— (For Experiment Agent)

## ğŸ“‹ å‘ç°çš„é—®é¢˜æ€»ç»“

åŸå§‹`modal_phase3_libero_eval.py`ä¸­å‘ç°äº†**12ä¸ªè‡´å‘½é—®é¢˜**ï¼š

### ä½ æœ‹å‹æŒ‡å‡ºçš„5ä¸ªé—®é¢˜ï¼š
1. âŒ **å®Œå…¨ç¼ºå¤±Speculative Decodingé€»è¾‘** - åŠ è½½äº†Draft Modelä½†ä»æœªä½¿ç”¨
2. âŒ **æ•°æ®æµæ–­è£‚** - `predict_action()`æ˜¯é»‘ç›’ï¼Œæ‹¿ä¸åˆ°hidden states
3. âŒ **éšæœºåˆå§‹åŒ–action_head** - ä¸´æ—¶åˆ›å»ºçš„headè¾“å‡ºéšæœºå™ªå£°
4. âŒ **å›¾åƒé¢„å¤„ç†ç¼ºå¤±** - åˆ‡æ¢åˆ°æ‰‹åŠ¨å‰å‘ä¼ æ’­åä¼šç¼ºå°‘é¢„å¤„ç†
5. âŒ **RFSQè§£ç é€»è¾‘æœªè¿æ¥** - å®šä¹‰äº†decoderä½†ä»æœªè°ƒç”¨

### é¢å¤–å‘ç°çš„7ä¸ªé—®é¢˜ï¼š
6. âŒ **Draft Modelç»´åº¦ä¸åŒ¹é…** - OpenVLAè¾“å‡º4096ç»´ï¼ŒDraftæœŸæœ›512ç»´
7. âŒ **RFSQ Head shapeç†è§£é”™è¯¯** - æ³¨é‡Šè¯¯å¯¼ï¼Œç»´åº¦è½¬æ¢é”™è¯¯
8. âŒ **Chunkæ‰§è¡Œé€»è¾‘ä¸å®Œæ•´** - é¢„æµ‹8æ­¥ä½†åªæ‰§è¡Œç¬¬1æ­¥
9. âŒ **æˆåŠŸåˆ¤å®šæœ‰bug** - timeoutä¼šè¢«è¯¯åˆ¤ä¸ºæˆåŠŸ
10. âŒ **ç¼ºå°‘projection layer** - æ— æ³•è¿æ¥OpenVLAå’ŒDraft Model
11. âš ï¸ **OpenVLA APIä½¿ç”¨ä¸æ˜ç¡®** - éœ€è¦è°ƒç ”å¦‚ä½•è·å–hidden states
12. âš ï¸ **Action denormalizationç¼ºå¤±** - å¯èƒ½å½±å“æ€§èƒ½

**ç»“æœ**ï¼šæˆåŠŸç‡ä¸º0%ï¼Œå› ä¸ºä½¿ç”¨äº†æœªè®­ç»ƒçš„æ¨¡å‹ + é€»è¾‘å®Œå…¨é”™è¯¯ã€‚

---

## âœ… ä¿®å¤æ–¹æ¡ˆ

æˆ‘ä»¬æä¾›äº†**å®Œå…¨é‡å†™**çš„æ­£ç¡®å®ç°ï¼š

### æ–°å¢æ–‡ä»¶

1. **`rsd_engine_core.py`** - æ ¸å¿ƒRSD Engineï¼ˆçº¯Pythonï¼ŒModal-agnosticï¼‰
   - å®Œæ•´çš„Speculative Decodingé€»è¾‘
   - æ­£ç¡®çš„æ•°æ®æµï¼šè¾“å…¥ â†’ Hidden States â†’ Token Prediction â†’ RFSQ Decoding
   - Draft projection layer (4096â†’512)
   - æ­£ç¡®çš„shapeè½¬æ¢
   - Chunkæ‰§è¡Œè¾…åŠ©å‡½æ•°

2. **`CORRECTED_ENGINE_TEMPLATE.py`** - è¯¦ç»†çš„å®ç°æ¨¡æ¿ï¼ˆå«æ³¨é‡Šï¼‰

3. **æœ¬æ–‡ä»¶** - Agentå®ç°æŒ‡å—

---

## ğŸš€ ä½ çš„ä»»åŠ¡

### Step 1: ç†è§£æ ¸å¿ƒå®ç°

é˜…è¯»`rsd_engine_core.py`ï¼Œäº†è§£æ­£ç¡®çš„æ•°æ®æµï¼š

```
Image + Text
  â†“ [processoré¢„å¤„ç†]
Inputs (pixel_values, input_ids)
  â†“ [OpenVLA forward]
Hidden States [Batch=1, Seq, Hidden=4096]
  â†“ [å–æœ€åä¸€ä¸ªtoken]
Last Hidden State [1, 4096]
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Draft Path (åŠ é€Ÿ)    â”‚ Main Path (å‡†ç¡®)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Projection (4096â†’512)â”‚ RFSQ Head (4096â†’...)â”‚
â”‚ Draft Model         â”‚ 8 Linear Heads      â”‚
â”‚ Coarse 3 Layers     â”‚ All 8 Layers        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“ [Comparison & Fusion]
Final Tokens [1, 8, 8, 16]
  â†“ [Permute: Layersç»´åº¦ç§»åˆ°æœ€å]
Tokens [1, 8, 16, 8]
  â†“ [RFSQ Decoder]
Actions [1, 8, 7]
```

### Step 2: åœ¨Modalç¯å¢ƒä¸­ä½¿ç”¨

ä½ éœ€è¦åœ¨Modalè„šæœ¬ä¸­ï¼š

#### A. å¯¼å…¥æ ¸å¿ƒengine

```python
# åœ¨modal_phase3_libero_eval.pyå¼€å¤´
# ç¡®ä¿rsd_engine_core.pyåœ¨åŒä¸€ç›®å½•æˆ–Python pathä¸­

from rsd_engine_core import RSDInferenceEngine, run_episode_with_chunks
```

#### B. ä¿®å¤æ¨¡å‹åŠ è½½ï¼ˆç¬¬302è¡Œï¼‰

```python
# âŒ é”™è¯¯ï¼š
base_model_name = "openvla/openvla-7b"

# âœ… æ­£ç¡®ï¼š
base_model_name = "moojink/openvla-7b-oft-finetuned-libero-spatial"
```

#### C. æ›¿æ¢SimpleRSDEngineï¼ˆç¬¬530-611è¡Œï¼‰

åˆ é™¤æ•´ä¸ª`SimpleRSDEngine`ç±»ï¼Œä½¿ç”¨ï¼š

```python
# åˆ›å»ºEngine
from rsd_engine_core import create_rsd_engine

engine = create_rsd_engine(
    main_model=main_model,
    draft_model=draft_model if use_speculative_decoding else None,
    rfsq_head=main_model.rfsq_head,  # å·²åŠ è½½çš„RFSQ head
    rfsq_decoder=rfsq_model,          # å·²åŠ è½½çš„RFSQ decoder
    processor=processor,
    device=device,
    chunk_len=8,
    action_dim=7,
)
```

#### D. ä¿®å¤Episode Loopï¼ˆç¬¬683-743è¡Œï¼‰

ä½¿ç”¨`run_episode_with_chunks`æ›¿ä»£æ‰‹åŠ¨å¾ªç¯ï¼š

```python
# åœ¨Taskå¾ªç¯ä¸­
for trial_idx in range(min(num_trials, len(init_states))):
    try:
        # åˆ›å»ºç¯å¢ƒ
        env = OffScreenRenderEnv(...)
        env.reset()
        obs = env.set_init_state(init_states[trial_idx])

        # è¿è¡Œepisode
        result = run_episode_with_chunks(
            env=env,
            engine=engine,
            task_description=task_description,
            max_steps=300,
            use_speculative_decoding=use_speculative_decoding,
            verbose=(trial_idx == 0),  # ç¬¬ä¸€ä¸ªtrialæ‰“å°è¯¦ç»†ä¿¡æ¯
        )

        # è®°å½•ç»“æœ
        success = result['success']
        episode_time = result['steps'] * 0.1  # ä¼°ç®—
        episode_inference_time = result['inference_time_ms'] / 1000

        if success:
            task_successes += 1
            total_successes += 1

        total_inference_time += episode_inference_time

        print(f"   Trial {trial_idx + 1}/{num_trials}: "
              f"{'âœ“' if success else 'âœ—'} "
              f"(steps: {result['steps']}, inf: {result['inference_time_ms']:.1f}ms)")

        env.close()

    except Exception as e:
        print(f"   âŒ Trial {trial_idx + 1} failed: {e}")
        continue
```

#### E. æ·»åŠ æœ€ç»ˆç»Ÿè®¡

```python
# åœ¨evaluationç»“æŸå
engine_stats = engine.get_stats()
print(f"\nğŸ“Š RSD Engine Statistics:")
print(f"   Total inferences: {engine_stats['total_inferences']}")
print(f"   Avg inference time: {engine_stats['avg_inference_time_ms']:.1f}ms")
if use_speculative_decoding:
    print(f"   Avg draft time: {engine_stats['avg_draft_time_ms']:.1f}ms")
    print(f"   Avg main time: {engine_stats['avg_main_time_ms']:.1f}ms")
    print(f"   Draft acceptance rate: {engine_stats['avg_acceptance_rate']:.1%}")
```

---

## ğŸ” å…³é”®æ£€æŸ¥ç‚¹

### æµ‹è¯•1: æ¨¡å‹åŠ è½½ï¼ˆModal image buildåï¼‰

è¿è¡Œ`--num-trials 1`ï¼Œæ£€æŸ¥logsï¼š

```
âœ“ Base OpenVLA-OFT model loaded
âœ“ RFSQ Decoder loaded (epoch X)
âœ“ RFSQ head loaded (val_acc: 0.909)
âœ“ Draft Model loaded (4.7M params)
âœ“ RSD Inference Engine created
   Hidden size: 4096
   Draft hidden size: 512
   Chunk length: 8
   Action dim: 7
```

### æµ‹è¯•2: ç¬¬ä¸€æ¬¡æ¨ç†ï¼ˆverbose=Trueï¼‰

åº”è¯¥çœ‹åˆ°ï¼š

```
      Input keys: dict_keys(['pixel_values', 'input_ids', ...])
      Pixel values shape: torch.Size([1, 3, 224, 224])
      Hidden state shape: torch.Size([1, 4096])
      Hidden state range: [-2.345, 3.210]
      Draft time: 15.3ms
      Draft tokens shape: torch.Size([1, 3, 1])
      Sample draft tokens: tensor([3, 4, 2])
      Main time: 45.7ms
      Main tokens shape: torch.Size([1, 8, 8, 16])
      Sample main tokens [0,0,0,:5]: tensor([3, 4, 3, 2, 5])
      Acceptance rate: 66.7%
      Decode time: 2.1ms
      Tokens for decoder: torch.Size([1, 8, 16, 8])
      Actions shape: (8, 7)
      Action range: [-0.856, 0.923]
      Sample action[0]: [ 0.234 -0.123  0.456  0.012 -0.234  0.567 -0.890]
```

### æµ‹è¯•3: Episodeå®Œæˆ

```
   Trial 1/1: âœ“ (steps: 127, inf: 285.3ms)
```

**å¦‚æœæˆåŠŸ**ï¼šç»§ç»­è¿è¡Œæ›´å¤štrials

**å¦‚æœå¤±è´¥**ï¼šæ ¹æ®é”™è¯¯ä¿¡æ¯è°ƒè¯•ï¼ˆå‚è€ƒä¸‹é¢çš„æ•…éšœæ’æŸ¥ï¼‰

---

## ğŸ› æ•…éšœæ’æŸ¥

### é”™è¯¯1: "Hidden state extraction failed"

**åŸå› **ï¼šOpenVLAçš„APIè°ƒç”¨æ–¹å¼ä¸å¯¹

**æ£€æŸ¥**ï¼š
```python
# å°è¯•ä¸åŒçš„å‚æ•°ç»„åˆ
outputs = self.main_model(
    input_ids=inputs['input_ids'],
    pixel_values=inputs['pixel_values'],
    attention_mask=inputs.get('attention_mask'),
    output_hidden_states=True,
)
```

### é”™è¯¯2: "Draft prediction failed: dimension mismatch"

**åŸå› **ï¼šDraft Modelè®­ç»ƒæ—¶çš„è¾“å…¥æ ¼å¼ä¸æ¨ç†ä¸ä¸€è‡´

**ä¿®å¤**ï¼šæ£€æŸ¥Phase 2è®­ç»ƒä»£ç ï¼Œç¡®è®¤Draft ModelæœŸæœ›çš„è¾“å…¥shape

å¯èƒ½éœ€è¦è°ƒæ•´ï¼š
```python
# å¦‚æœDraft ModelæœŸæœ›flattened input
draft_input = draft_input.view(1, -1)  # Flatten
```

### é”™è¯¯3: "RFSQ decoding failed: shape mismatch"

**åŸå› **ï¼šToken shapeè½¬æ¢é”™è¯¯

**æ£€æŸ¥**ï¼š
```python
print(f"Main tokens: {main_tokens.shape}")  # åº”è¯¥æ˜¯ [1, 8, 8, 16]
print(f"After permute: {final_tokens_reshaped.shape}")  # åº”è¯¥æ˜¯ [1, 8, 16, 8]
```

### é”™è¯¯4: Actionså…¨æ˜¯0æˆ–NaN

**åŸå› **ï¼šRFSQ decoderæ²¡æœ‰æ­£ç¡®åŠ è½½

**æ£€æŸ¥**ï¼š
```python
# æµ‹è¯•decoder
test_indices = torch.randint(0, 7, (1, 8, 16, 8)).to(device)
test_actions = rfsq_decoder.decode_from_indices(test_indices)
print(f"Test actions range: [{test_actions.min():.3f}, {test_actions.max():.3f}]")
```

### é”™è¯¯5: æˆåŠŸç‡ä»ç„¶å¾ˆä½ï¼ˆ<50%ï¼‰

**å¯èƒ½åŸå› **ï¼š
1. RFSQ headè®­ç»ƒè´¨é‡ä¸å¥½ï¼ˆæ£€æŸ¥Phase 2çš„90.9% accuracyæ˜¯å¦çœŸå®ï¼‰
2. RFSQ decoderé‡æ„è¯¯å·®å¤ªå¤§ï¼ˆæ£€æŸ¥Phase 1çš„MSEï¼‰
3. Action normalizationä¸ä¸€è‡´ï¼ˆæ£€æŸ¥è®­ç»ƒæ—¶çš„normalizationæ–¹å¼ï¼‰

**è°ƒè¯•**ï¼šè¿è¡Œbaselineï¼ˆä¸ä½¿ç”¨RFSQï¼‰å¯¹æ¯”ï¼š
```python
# ä¸´æ—¶ä¿®æ”¹ï¼šç›´æ¥ç”¨OpenVLAçš„predict_action
action = main_model.predict_action(
    image, task_description, unnorm_key="libero_spatial"
)
```

å¦‚æœbaselineæˆåŠŸç‡>90%ï¼Œè¯´æ˜æ˜¯RFSQ pipelineçš„é—®é¢˜ã€‚

---

## ğŸ“Š é¢„æœŸç»“æœ

### ä¿®å¤åçš„æ€§èƒ½æŒ‡æ ‡

| Metric | Baseline (L1 Regression) | RSD (RFSQ Tokens) | Target |
|--------|-------------------------|-------------------|--------|
| Success Rate | 97.1% | 85-95% | âœ… |
| Inference Time | ~70ms | 45-55ms | âœ… 1.3-1.6x faster |
| Draft Acceptance | N/A | 60-80% | âœ… |
| Memory Usage | High (variable padding) | Low (fixed size) | âœ… |

**å…³é”®ç‚¹**ï¼š
- æˆåŠŸç‡è½»å¾®ä¸‹é™ï¼ˆ2-12%ï¼‰æ˜¯**æ­£å¸¸çš„**ï¼Œå› ä¸ºRFSQé‡åŒ–ä¼šæœ‰å™ªå£°
- æ¨ç†é€Ÿåº¦åº”è¯¥æ˜¾è‘—æå‡ï¼ˆå¦‚æœDraft Modelå·¥ä½œæ­£å¸¸ï¼‰
- Acceptance rateè¶Šé«˜ï¼ŒåŠ é€Ÿæ•ˆæœè¶Šå¥½

---

## ğŸ¯ æµ‹è¯•æµç¨‹

### é˜¶æ®µ1: å•æ¬¡æµ‹è¯•ï¼ˆéªŒè¯åŸºæœ¬åŠŸèƒ½ï¼‰

```bash
modal run modal_phase3_libero_eval.py \
    --task-suite libero_spatial \
    --num-trials 1 \
    --use-speculative-decoding False  # å…ˆä¸ç”¨Draft Model
```

**æœŸæœ›**ï¼šè‡³å°‘1ä¸ªtrialæˆåŠŸ

### é˜¶æ®µ2: å°è§„æ¨¡æµ‹è¯•ï¼ˆéªŒè¯ç¨³å®šæ€§ï¼‰

```bash
modal run modal_phase3_libero_eval.py \
    --task-suite libero_spatial \
    --num-trials 5 \
    --use-speculative-decoding False
```

**æœŸæœ›**ï¼šæˆåŠŸç‡ > 70%

### é˜¶æ®µ3: å¯ç”¨Speculative Decoding

```bash
modal run modal_phase3_libero_eval.py \
    --task-suite libero_spatial \
    --num-trials 5 \
    --use-speculative-decoding True
```

**æœŸæœ›**ï¼š
- æˆåŠŸç‡ä¸é˜¶æ®µ2æ¥è¿‘
- æ¨ç†æ—¶é—´å‡å°‘30-50%
- Draft acceptance rate > 50%

### é˜¶æ®µ4: å®Œæ•´è¯„ä¼°

```bash
modal run modal_phase3_libero_eval.py \
    --task-suite libero_spatial \
    --num-trials 50 \
    --use-speculative-decoding True
```

**æœŸæœ›**ï¼š
- æ€»ä½“æˆåŠŸç‡ 85-95%
- å¹³å‡æ¨ç†æ—¶é—´ 45-55ms
- ç¨³å®šçš„acceptance rate

---

## ğŸ“ æäº¤Checklist

ä¿®å¤å®Œæˆåï¼Œç¡®è®¤ä»¥ä¸‹å†…å®¹ï¼š

- [ ] ä½¿ç”¨æ­£ç¡®çš„base model (`moojink/openvla-7b-oft-finetuned-libero-spatial`)
- [ ] å¯¼å…¥å¹¶ä½¿ç”¨`rsd_engine_core.py`
- [ ] åˆ é™¤äº†é”™è¯¯çš„`SimpleRSDEngine`å®ç°
- [ ] ä½¿ç”¨`run_episode_with_chunks`æ‰§è¡Œepisodes
- [ ] ä¿®å¤äº†æˆåŠŸåˆ¤å®šé€»è¾‘ï¼ˆ`info_env.get('success', False)`ï¼‰
- [ ] è¿è¡Œ`--num-trials 1`éªŒè¯ä¸crash
- [ ] è¿è¡Œ`--num-trials 5`éªŒè¯æˆåŠŸç‡>70%
- [ ] å¯ç”¨speculative decodingéªŒè¯åŠ é€Ÿæ•ˆæœ
- [ ] è®°å½•æœ€ç»ˆçš„success rateå’Œtiming statistics

---

## ğŸ‰ æ€»ç»“

**å…³é”®ä¿®å¤**ï¼š
1. âœ… ä½¿ç”¨fine-tunedæ¨¡å‹è€Œä¸æ˜¯åŸç‰ˆOpenVLA
2. âœ… å®ç°å®Œæ•´çš„Speculative Decodingé€»è¾‘
3. âœ… æ­£ç¡®çš„æ•°æ®æµï¼šHidden States â†’ Token Prediction â†’ RFSQ Decoding
4. âœ… æ·»åŠ Draft projection layer
5. âœ… æ­£ç¡®çš„shapeè½¬æ¢å’Œchunkæ‰§è¡Œ

**ä¸ºä»€ä¹ˆä¹‹å‰å¤±è´¥**ï¼š
- åŸç‰ˆOpenVLAä¸çŸ¥é“å¦‚ä½•åšLIBEROä»»åŠ¡ â†’ 0% success
- æ²¡æœ‰ä½¿ç”¨è®­ç»ƒå¥½çš„RFSQ pipeline â†’ æ— æ³•è¯„ä¼°RSD
- é”™è¯¯è¢«éšè—ï¼ˆéšæœºåŠ¨ä½œï¼‰ â†’ çœ‹ä¸åˆ°çœŸæ­£çš„é—®é¢˜

**ç°åœ¨åº”è¯¥è¾¾åˆ°**ï¼š
- 85-95% success rate
- 45-55ms inference time
- 1.3-1.6x speedup with speculative decoding

---

**Good luck! ğŸš€**

å¦‚æœ‰é—®é¢˜ï¼Œæ£€æŸ¥ï¼š
1. æ¨¡å‹åŠ è½½logs
2. ç¬¬ä¸€æ¬¡æ¨ç†çš„è¯¦ç»†è¾“å‡ºï¼ˆverbose=Trueï¼‰
3. Shape mismatché”™è¯¯
4. RFSQ decoderæ˜¯å¦æ­£ç¡®å·¥ä½œ
